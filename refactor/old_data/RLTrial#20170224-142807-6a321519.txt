choice_noise = 0.05
n_intervals = 10
neuron_type = 'default'
N_state_action = 500
D = 5
direct = False
seed = 2
T_interval = 0.05
alpha = 0.3
dt = 0.001
env_seed = 8
backend = 'nengo'

stay_prob = array([[ nan,   1.],
       [ nan,   1.]])
rewards = [True, True, True, True, True]
history = [(1, 'SB'), (1, 'SB'), (1, 'SA'), (1, 'SA'), (1, 'SA')]
